name: ‚è¨ Download Memes

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:
    inputs:
      disable_cache_check:
        description: 'Disable cache check (true/false)'
        required: false
        default: false
        type: boolean
      show_debug:
        description: 'Enable debug messages (true/false)'
        required: false
        default: false
        type: boolean
      post_limit:
        description: 'Number of posts to fetch from each subreddit'
        required: false
        default: '5'
        type: string

jobs:
  download-memes:
    name: üåê Download Memes
    runs-on: ubuntu-latest
    outputs:
      metadata: ${{ steps.collect-metadata.outputs.metadata }}
    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4

      - name: üì¶ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: üßπ Remove Cache
        uses: DareFox/delete-cache-by-key@v1
        with:
          key: meme-ids-cache-
          mode: exact
        continue-on-error: true

      - name: üöÄ Restore Meme IDs Cache
        id: restore-cache
        uses: actions/cache@v4
        with:
          path: cache/meme_ids.json
          key: meme-ids-cache-
          restore-keys: |
            meme-ids-cache-

      - name: üß∞ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install praw requests yt-dlp

      - name: üîß Install Rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash

      - name: üìÇ Set Up Rclone Config
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.PIXELDRAIN_CONF }}" > ~/.config/rclone/rclone.conf

      - name: ‚è¨ Download Reddit Posts
        id: download-memes
        env:
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          DISABLE_CACHE_CHECK: ${{ github.event.inputs.disable_cache_check }}
          SHOW_DEBUG: ${{ github.event.inputs.show_debug || true }}
          POST_LIMIT: ${{ github.event.inputs.post_limit || '5' }}
        run: |
          mkdir -p cache
          python - <<EOF
          import os
          import json
          import requests
          import praw
          import yt_dlp

          client_id = os.getenv("CLIENT_ID")
          client_secret = os.getenv("CLIENT_SECRET")
          user_agent = os.getenv("USER_AGENT")
          disable_cache_check = os.getenv("DISABLE_CACHE_CHECK", "false").lower() == "true"
          show_debug = os.getenv("SHOW_DEBUG", "false").lower() == "true"
          post_limit = int(os.getenv("POST_LIMIT", "5"))
          MEME_LIMIT = 250

          def debug_log(msg):
              if show_debug:
                  print(f"üõ†Ô∏è DEBUG: {msg}")

          reddit = praw.Reddit(
              client_id=client_id,
              client_secret=client_secret,
              user_agent=user_agent,
          )

          cache_file = "cache/meme_ids.json"
          try:
              with open(cache_file, "r") as f:
                  cached_ids = set(json.load(f))
          except:
              cached_ids = set()

          valid_image_exts = ['.png','.jpg','.jpeg','.webp','.gif']
          subreddits = [
              "memes", "ProgrammerHumor", "dankmemes", "DirtyMemes",
              "rule34", "rareinsults", "futanari", "HardPornGifs",
              "funny", "pics", "science", "todayilearned",
              "porn_gifs", "MemeVideos"
          ]
          total_memes = 0
          new_ids = []
          memes_metadata = []

          for subreddit in subreddits:
              if total_memes >= MEME_LIMIT:
                  break
              debug_log(f"Scraping r/{subreddit} for new posts...")
              for post in reddit.subreddit(subreddit).new(limit=post_limit):
                  if not disable_cache_check and post.id in cached_ids:
                      continue
                  try:
                      ext = os.path.splitext(post.url.lower())[1]
                      if ext in valid_image_exts:
                          debug_log(f"Found image post: {post.id}")
                          r = requests.get(post.url, timeout=10)
                          r.raise_for_status()
                          out_fname = os.path.join("cache", f"{post.id}{ext}")
                          with open(out_fname, "wb") as f:
                              f.write(r.content)
                          memes_metadata.append({
                              "id": post.id,
                              "title": post.title,
                              "author": str(post.author) if post.author else "Unknown",
                              "subreddit": str(post.subreddit),
                              "upvotes": post.ups,
                              "filename": os.path.basename(out_fname),
                              "type": "image"
                          })
                          new_ids.append(post.id)
                          total_memes += 1
                      else:
                          debug_log(f"Possible video post: {post.id}")
                          outtmpl = f"cache/{post.id}.%(ext)s"
                          ydl_opts = {
                              'outtmpl': outtmpl,
                              'quiet': not show_debug,
                              'no_warnings': True,
                              'ignoreerrors': True,
                              'format': 'bestvideo+bestaudio/best',
                              'merge_output_format': 'mp4',
                          }
                          with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                              ydl.download([post.url])
                          downloaded_file = None
                          for file in os.listdir("cache"):
                              if file.startswith(post.id):
                                  downloaded_file = os.path.join("cache", file)
                                  break
                          if downloaded_file:
                              debug_log(f"Found video file: {downloaded_file}")
                              memes_metadata.append({
                                  "id": post.id,
                                  "title": post.title,
                                  "author": str(post.author) if post.author else "Unknown",
                                  "subreddit": str(post.subreddit),
                                  "upvotes": post.ups,
                                  "filename": os.path.basename(downloaded_file),
                                  "type": "video"
                              })
                              new_ids.append(post.id)
                              total_memes += 1
                          else:
                              print(f"‚ö†Ô∏è Post {post.id}: Could not save as image or video - skipping.")
                  except Exception as e:
                      print(f"‚ö†Ô∏è Error processing post {post.id}: {e}")

          if new_ids:
              cached_ids.update(new_ids)
              with open(cache_file, "w") as f:
                  json.dump(sorted(cached_ids), f)
              print(f"üéâ Downloaded {len(new_ids)} new items.")
          else:
              print("‚ú® No New Items Found!")
          with open("cache/memes_metadata.json", "w") as f:
              json.dump(memes_metadata, f, indent=2)
          EOF

      - name: üóÇÔ∏è Collect Metadata
        id: collect-metadata
        run: |
          # Limit to first 250 memes to prevent matrix overflow
          limited_metadata=$(jq '.[:250]' cache/memes_metadata.json)
          metadata=$(echo "$limited_metadata" | jq -c .)
          echo "metadata=$metadata" >> $GITHUB_OUTPUT

      - name: üåê Upload Memes with Rclone
        run: |
          rclone copy cache Pixeldrain:"üíØ Memes"

      - name: üîß Compute Hash of Updated meme_ids.json
        id: compute-hash
        run: |
          if [ -f cache/meme_ids.json ]; then
            FILE_HASH=$(sha256sum cache/meme_ids.json | awk '{print $1}')
          else
            FILE_HASH="empty-cache"
          fi
          echo "hash=$FILE_HASH" >> $GITHUB_ENV

      - name: üíæ Update Meme IDs Cache
        uses: actions/cache@v4
        with:
          path: cache/meme_ids.json
          key: meme-ids-cache-${{ env.hash }}

      - name: üìú List All Files
        run: |
          tree

      - name: üì§ Upload Cache as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: cache
          path: cache/

  send-to-telegram:
    needs: download-memes
    name: üì§ Send All Memes to Telegram
    runs-on: ubuntu-latest
    steps:
      - name: üì• Check Out Repository
        uses: actions/checkout@v4

      - name: üì§ Download Cache Artifact
        uses: actions/download-artifact@v4
        with:
          name: cache
          path: cache/

      - name: üì¶ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: üß∞ Install Python Dependencies
        run: |
          pip install python-telegram-bot

      - name: üì§ Send Memes in One Script
        run: |
          python - <<'EOF'
          import os
          import re
          import json
          import asyncio
          from telegram import Bot

          BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
          CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
          METADATA_FILE = 'cache/memes_metadata.json'

          def escape_markdown(text):
              """Escapes Markdown-sensitive characters."""
              escape_chars = r"_*[]()~`>#+-=|{}.!"
              return re.sub(f'([{"".join(re.escape(c) for c in escape_chars)}])', r'\\\1', text)

          def build_caption(meme):
              if meme['type'] == 'image':
                  return f"""üéâ **New Meme Alert!**
          üìú *Title:* {escape_markdown(meme.get('title', 'No Title'))}
          üñãÔ∏è *Author:* {escape_markdown(meme.get('author', 'Unknown'))}
          üëç *Upvotes:* {meme.get('upvotes', '0')}
          üîó *URL:* [View Post]({meme.get('url', '')})
          üè∑Ô∏è *Subreddit:* r/{escape_markdown(meme.get('subreddit', '?'))}"""
              else:
                  return f"""üéâ **New Video Meme Alert!**
          üìú *Title:* {escape_markdown(meme.get('title', 'No Title'))}
          üñãÔ∏è *Author:* {escape_markdown(meme.get('author', 'Unknown'))}
          üëç *Upvotes:* {meme.get('upvotes', '0')}
          üîó *URL:* [View Post]({meme.get('url', '')})
          üè∑Ô∏è *Subreddit:* r/{escape_markdown(meme.get('subreddit', '?'))}"""

          async def send_meme_async(bot, meme):
              file_path = os.path.join('cache', meme['filename'])
              caption = build_caption(meme)
              if meme['type'] == 'image':
                  with open(file_path, 'rb') as img:
                      await bot.send_photo(
                          chat_id=CHAT_ID,
                          photo=img,
                          caption=caption,
                          parse_mode='Markdown'
                      )
              elif meme['type'] == 'video':
                  with open(file_path, 'rb') as vid:
                      await bot.send_video(
                          chat_id=CHAT_ID,
                          video=vid,
                          caption=caption,
                          parse_mode='Markdown',
                          supports_streaming=True
                      )

          async def main():
              bot = Bot(token=BOT_TOKEN)
              if not os.path.exists(METADATA_FILE):
                  print("No metadata file found. Nothing to send.")
                  return

              with open(METADATA_FILE, 'r') as f:
                  memes = json.load(f)

              for meme in memes:
                  try:
                      await send_meme_async(bot, meme)
                      print(f"Sent {meme['type']} with ID: {meme['id']}")
                  except Exception as e:
                      print(f"Failed to send {meme['id']}: {e}")

          if __name__ == '__main__':
              try:
                  asyncio.run(main())
              except Exception as e:
                  print(f"Error sending memes in batch: {e}")
          EOF
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_TO }}
        continue-on-error: true
