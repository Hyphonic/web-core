name: Download Memes From Reddit

on:
  schedule:
    - cron: '0 * * * *' # Runs every hour
  workflow_dispatch: # Allows manual triggering of the workflow

jobs:
  download-memes:
    name: üåê Download Memes
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4

      - name: üì¶ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: üß∞ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade git+https://github.com/praw-dev/praw.git
          pip install requests

      - name: üîÑ Restore Cache
        id: cache-restore
        uses: actions/cache@v4
        with:
          path: cache/memes.json
          key: reddit-memes-cache

      - name: ‚è¨ Download Latest Memes
        id: download-memes
        env:
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: |
          mkdir -p cache
          touch cache/memes.json
          python - <<EOF
          import os
          import json
          import praw
          import requests

          # Environment variables for credentials
          client_id = os.getenv("CLIENT_ID")
          client_secret = os.getenv("CLIENT_SECRET")
          user_agent = os.getenv("USER_AGENT")

          # Initialize Reddit in read-only mode
          reddit = praw.Reddit(
              client_id=client_id,
              client_secret=client_secret,
              user_agent=user_agent,
          )

          # Load cached URLs
          cache_file = "cache/memes.json"
          try:
              with open(cache_file, "r") as f:
                  cached_urls = set(json.load(f))
          except (FileNotFoundError, json.JSONDecodeError):
              cached_urls = set()

          # Create a directory for images
          os.makedirs("cache", exist_ok=True)

          # Fetch new posts from r/memes
          new_urls = []
          for post in reddit.subreddit("memes").new(limit=10):
              if post.url.endswith((".png", ".jpg", ".jpeg")) and post.url not in cached_urls:
                  print(f"üéâ New Meme Found:\n  Title: {post.title}\n  Author: u/{post.author}\n  Upvotes: {post.score}\n  URL: {post.url}\n")
                  
                  # Save the image
                  filename = os.path.join("cache", os.path.basename(post.url))
                  with open(filename, "wb") as f:
                      f.write(requests.get(post.url).content)
                  new_urls.append(post.url)

          # Update cache
          cached_urls.update(new_urls)
          with open(cache_file, "w") as f:
              json.dump(list(cached_urls), f)

          if not new_urls:
              print("‚ú® No New Memes Found!")
          EOF

      - name: üõ†Ô∏è Save Artifacts
        if: steps.download-memes.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: memes
          path: cache/*.png,cache/*.jpg,cache/*.jpeg

      - name: üßπ Update Cache
        if: steps.download-memes.outcome == 'success'
        uses: actions/cache@v4
        with:
          path: cache/memes.json
          key: reddit-memes-cache
