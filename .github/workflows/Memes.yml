name: Download Memes From Reddit

on:
  schedule:
    - cron: '0 * * * *' # Runs every hour
  workflow_dispatch:
    inputs:
      disable_cache_check:
        description: 'Disable cache check (true/false)'
        required: false
        default: 'false'
        type: boolean
      show_debug:
        description: 'Enable debug messages (true/false)'
        required: false
        default: 'true'
        type: boolean

jobs:
  download-memes:
    name: üåê Download Memes
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4

      - name: üì¶ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: üß∞ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install praw

      - name: üìÇ Set Up Rclone Config
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.PIXELDRAIN_CONF }}" > ~/.config/rclone/rclone.conf

      - name: üîÑ Restore Cache
        id: cache-restore
        uses: actions/cache@v4
        with:
          path: cache/memes.json
          key: reddit-memes-cache

      - name: ‚è¨ Download Latest Memes
        id: download-memes
        env:
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          DISABLE_CACHE_CHECK: ${{ github.event.inputs.disable_cache_check }}
          SHOW_DEBUG: ${{ github.event.inputs.show_debug }}
        run: |
          mkdir -p cache
          touch cache/memes.json
          python - <<EOF
          import os
          import json
          import requests
          import praw

          # Environment variables
          client_id = os.getenv("CLIENT_ID")
          client_secret = os.getenv("CLIENT_SECRET")
          user_agent = os.getenv("USER_AGENT")
          disable_cache_check = os.getenv("DISABLE_CACHE_CHECK", "false").lower() == "true"
          show_debug = os.getenv("SHOW_DEBUG", "true").lower() == "true"

          # Helper function for debug logging
          def debug_log(message):
              if show_debug:
                  print(f"üîß DEBUG: {message}")

          debug_log("Initializing Reddit client in read-only mode...")
          reddit = praw.Reddit(
              client_id=client_id,
              client_secret=client_secret,
              user_agent=user_agent,
          )

          # Load cached URLs
          cache_file = "cache/memes.json"
          debug_log(f"Loading cached URLs from {cache_file}...")
          try:
              with open(cache_file, "r") as f:
                  cached_urls = set(json.load(f))
              debug_log(f"{len(cached_urls)} cached URLs loaded.")
          except (FileNotFoundError, json.JSONDecodeError) as e:
              debug_log(f"Cache file not found or invalid. Starting with an empty cache. Error: {e}")
              cached_urls = set()

          # Create a directory for images
          image_dir = "cache"
          os.makedirs(image_dir, exist_ok=True)
          debug_log(f"Ensured image directory exists at {image_dir}.")

          # Fetch new posts from r/memes
          debug_log("Fetching latest posts from r/memes...")
          new_urls = []
          valid_image_extensions = ['png', 'jpeg', 'jpg', 'webp']
          for post in reddit.subreddit("memes").new(limit=20):
              debug_log(f"Processing post: {post.title} | URL: {post.url}")

              # Only process if not cached or if cache check is disabled
              if disable_cache_check or post.url not in cached_urls:
                  debug_log(f"Cache check {'disabled' if disable_cache_check else 'enabled'}, processing URL: {post.url}")
                  try:
                      debug_log("Sending HEAD request to validate content type...")
                      response = requests.head(post.url, allow_redirects=True, timeout=5)
                      content_type = response.headers.get("Content-Type", "")
                      debug_log(f"Content-Type for {post.url} is {content_type}.")

                      # Check for valid image extensions or Content-Type
                      if content_type.startswith("image/") or any(ext in post.url.lower() for ext in valid_image_extensions):
                          print(f"üéâ New Meme Found:\n  Title: {post.title}\n  Author: u/{post.author}\n  Upvotes: {post.score}\n  URL: {post.url}")
                          
                          # Save the image
                          debug_log("Sending GET request to download the image...")
                          response = requests.get(post.url, timeout=10)
                          filename = os.path.join(image_dir, os.path.basename(post.url))
                          with open(filename, "wb") as f:
                              f.write(response.content)
                          debug_log(f"‚úÖ Image saved to {filename}.")
                          new_urls.append(post.url)
                      else:
                          debug_log(f"‚ö†Ô∏è Skipping Non-Image URL: {post.url}")
                  except requests.RequestException as e:
                      debug_log(f"‚ùå Failed to Process URL {post.url}. Error: {e}")
              else:
                  debug_log(f"‚ö†Ô∏è URL already cached and cache check enabled: {post.url}")

          # Update cache
          debug_log(f"Updating cache with {len(new_urls)} new URLs...")
          cached_urls.update(new_urls)
          with open(cache_file, "w") as f:
              json.dump(list(cached_urls), f)
          debug_log("‚úÖ Cache updated.")

          if not new_urls:
              print("‚ú® No New Memes Found!")
          else:
              print(f"üéâ {len(new_urls)} new memes downloaded.")
          EOF

      - name: üìú List All Files
        run: |
          tree

      - name: üåê Upload Memes with Rclone
        run: |
          rclone copy cache/*.jpeg Pixeldrain:"üíØ Memes"
          rclone copy cache/*.png Pixeldrain:"üíØ Memes"
          rclone copy cache/*.webp Pixeldrain:"üíØ Memes"

      - name: üõ†Ô∏è Save Artifacts
        if: steps.download-memes.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: memes
          path: |
            cache/*.jpeg
            cache/*.png
            cache/*.webp

      - name: üßπ Update Cache
        if: steps.download-memes.outcome == 'success'
        uses: actions/cache@v4
        with:
          path: cache/memes.json
          key: reddit-memes-cache
