name: Download Memes From Reddit

on:
  schedule:
    - cron: '*/20 * * * *'
  workflow_dispatch:
    inputs:
      disable_cache_check:
        description: 'Disable cache check (true/false)'
        required: false
        default: false
        type: boolean
      show_debug:
        description: 'Enable debug messages (true/false)'
        required: false
        default: false
        type: boolean

jobs:
  download-memes:
    name: üåê Download Memes
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout Code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          persist-credentials: false

      - name: üì¶ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: üß∞ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install praw requests

      - name: üîß Install Rclone
        run: |
          curl https://rclone.org/install.sh | sudo bash

      - name: üìÇ Set Up Rclone Config
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.PIXELDRAIN_CONF }}" > ~/.config/rclone/rclone.conf

      # 2) Download Latest Memes, updating or creating meme_ids.json
      - name: ‚è¨ Download Latest Memes
        id: download-memes
        env:
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          DISABLE_CACHE_CHECK: ${{ github.event.inputs.disable_cache_check }}
          SHOW_DEBUG: ${{ github.event.inputs.show_debug }}
        run: |
          mkdir -p cache
          python - <<EOF
          import os
          import json
          import requests
          import praw

          client_id = os.getenv("CLIENT_ID")
          client_secret = os.getenv("CLIENT_SECRET")
          user_agent = os.getenv("USER_AGENT")
          disable_cache_check = os.getenv("DISABLE_CACHE_CHECK", "false").lower() == "true"
          show_debug = os.getenv("SHOW_DEBUG", "false").lower() == "true"

          def debug_log(message):
              if show_debug:
                  print(f"üõ†Ô∏è DEBUG: {message}")

          debug_log("‚úÖ Initializing Reddit client in read-only mode...")
          reddit = praw.Reddit(
              client_id=client_id,
              client_secret=client_secret,
              user_agent=user_agent,
          )

          cache_file = "cache/meme_ids.json"
          debug_log(f"üîç Loading cached IDs from {cache_file}...")

          try:
              with open(cache_file, "r") as f:
                  cached_ids = set(json.load(f))
              debug_log(f"{len(cached_ids)} cached IDs loaded.")
              debug_log(f"All IDs: {cached_ids}")
          except (FileNotFoundError, json.JSONDecodeError) as e:
              debug_log(f"‚ö†Ô∏è No valid cache found. Error: {e}")
              cached_ids = set()

          image_dir = "cache"
          os.makedirs(image_dir, exist_ok=True)
          debug_log("üîÑ Fetching latest posts from r/memes...")
          new_ids = []
          valid_image_extensions = ['png','jpg','jpeg','webp','gif']

          for post in reddit.subreddit("memes").new(limit=20):
              debug_log(f"Processing post: {post.title} | ID: {post.id} | URL: {post.url}")
              if disable_cache_check or post.id not in cached_ids:
                  debug_log(f"üÜï Processing new ID: {post.id}")
                  try:
                      debug_log("Sending HEAD request...")
                      response = requests.head(post.url, allow_redirects=True, timeout=5)
                      content_type = response.headers.get("Content-Type", "")
                      debug_log(f"Content-Type: {content_type}")
                      if content_type.startswith("image/") or any(ext in post.url.lower() for ext in valid_image_extensions):
                          print(f"üéâ New Meme Found:\n  Title: {post.title}\n  Author: u/{post.author}\n  Upvotes: {post.score}\n  URL: {post.url}")
                          debug_log("Downloading image...")
                          response = requests.get(post.url, timeout=10)
                          filename = os.path.join(image_dir, os.path.basename(post.url))
                          with open(filename, "wb") as f:
                              f.write(response.content)
                          new_ids.append(post.id)
                      else:
                          debug_log("‚ö†Ô∏è Skipping non-image URL.")
                  except requests.RequestException as e:
                      debug_log(f"‚ùå Request failed: {e}")
              else:
                  debug_log(f"Already seen ID: {post.id}, skipping.")

          if new_ids:
              cached_ids.update(new_ids)
              with open(cache_file, "w") as f:
                  json.dump(list(cached_ids), f)
              debug_log(f"üìù Cache updated with IDs: {new_ids}")
              print(f"üéâ {len(new_ids)} new memes downloaded.")
          else:
              print("‚ú® No New Memes Found!")
          EOF

      - name: üìú List All Files
        run: |
          tree

      - name: üåê Upload Memes with Rclone
        run: |
          rclone copy cache Pixeldrain:"üíØ Memes"

      # 3) Save images as usual
      - name: üõ†Ô∏è Save Artifacts (Images)
        if: steps.download-memes.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: memes
          path: |
            cache/*.jpg
            cache/*.jpeg
            cache/*.png
            cache/*.webp
            cache/*.gif

      # 5) Commit and push the updated meme_ids.json back to the repository
      - name: üì§ Commit and Push meme_ids.json
        if: steps.download-memes.outcome == 'success'
        uses: EndBug/add-and-commit@v9
        with:
          message: "üîÑ Update meme_ids.json"
          default_author: github_actions
          committer_name: GitHub Actions
          add: 'cache'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
