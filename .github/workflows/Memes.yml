name: â¬ Download Memes

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:
    inputs:
      disable_cache_check:
        description: 'Disable cache check (true/false)'
        required: false
        default: false
        type: boolean
      show_debug:
        description: 'Enable debug messages (true/false)'
        required: false
        default: false
        type: boolean
      post_limit:
        description: 'Number of posts to fetch from each subreddit'
        required: false
        default: '5'
        type: string

jobs:
  download-memes:
    name: ğŸŒ Download Memes
    runs-on: ubuntu-latest
    outputs:
      metadata: ${{ steps.collect-metadata.outputs.metadata }}
    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: ğŸ§¹ Remove Cache
        uses: DareFox/delete-cache-by-key@v1
        with:
          key: meme-ids-cache-
          mode: exact
        continue-on-error: true

      - name: ğŸš€ Restore Meme IDs Cache
        id: restore-cache
        uses: actions/cache@v4
        with:
          path: cache/meme_ids.json
          key: meme-ids-cache-
          restore-keys: |
            meme-ids-cache-

      - name: ğŸ§° Install Dependencies
        run: |
          echo "ğŸ [DEBUG] Upgrading pip..."
          python -m pip install --upgrade pip
          echo "ğŸ“¦ [DEBUG] Installing PRAW, Requests, and yt_dlp..."
          pip install praw requests yt-dlp

      - name: ğŸ”§ Install Rclone
        run: |
          echo "ğŸ”„ [DEBUG] Installing Rclone..."
          curl https://rclone.org/install.sh | sudo bash

      - name: ğŸ“‚ Set Up Rclone Config
        run: |
          echo "ğŸ“ [DEBUG] Setting up Rclone configuration..."
          mkdir -p ~/.config/rclone
          echo "${{ secrets.PIXELDRAIN_CONF }}" > ~/.config/rclone/rclone.conf

      - name: â¬ Download Reddit Posts
        id: download-memes
        env:
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          DISABLE_CACHE_CHECK: ${{ github.event.inputs.disable_cache_check }}
          SHOW_DEBUG: ${{ github.event.inputs.show_debug || true }}
          POST_LIMIT: ${{ github.event.inputs.post_limit || '5' }}
        run: |
          echo "ğŸš€ [DEBUG] Starting meme download process..."
          mkdir -p cache
          python - <<EOF
          import os
          import json
          import requests
          import praw
          import yt_dlp

          client_id = os.getenv("CLIENT_ID")
          client_secret = os.getenv("CLIENT_SECRET")
          user_agent = os.getenv("USER_AGENT")
          disable_cache_check = os.getenv("DISABLE_CACHE_CHECK", "false").lower() == "true"
          show_debug = os.getenv("SHOW_DEBUG", "false").lower() == "true"
          post_limit = int(os.getenv("POST_LIMIT", "5"))
          MEME_LIMIT = 250

          def debug_log(msg):
              if show_debug:
                  print(f"ğŸ¯ [DEBUG] {msg}")

          reddit = praw.Reddit(
              client_id=client_id,
              client_secret=client_secret,
              user_agent=user_agent,
          )
          debug_log("âœ… Reddit instance created.")

          cache_file = "cache/meme_ids.json"
          try:
              with open(cache_file, "r") as f:
                  cached_ids = set(json.load(f))
              debug_log("ğŸ“‚ Loaded cached meme IDs.")
          except:
              cached_ids = set()
              debug_log("âš ï¸ No cache found. Starting fresh.")

          valid_image_exts = ['.png','.jpg','.jpeg','.webp','.gif']
          subreddits = [
              "memes", "ProgrammerHumor", "dankmemes", "DirtyMemes",
              "rule34", "rareinsults", "futanari", "HardPornGifs",
              "funny", "pics", "science", "todayilearned",
              "porn_gifs", "MemeVideos", "hentai", "boobs", "pussy", "meirl",
              "gifs", "aww", "videos", "AskReddit", "Holup", "wtf", "hmmm", "coolguides",
              "Unexpected", "Hentai_GIF", "horsecockfuta", "FutanariGifs",
              "Yiff", "trapHentai", "Fnafpornrp", "Futanari_Comics", "FutaCum",
              "Overwatch_Porn", "3DHentai"
          ]
          total_memes = 0
          new_ids = []
          memes_metadata = []

          for subreddit in subreddits:
              if total_memes >= MEME_LIMIT:
                  debug_log("ğŸ“Š Meme limit reached. Stopping download.")
                  break
              debug_log(f"ğŸ” Scraping r/{subreddit} for new posts...")
              for post in reddit.subreddit(subreddit).new(limit=post_limit):
                  if not disable_cache_check and post.id in cached_ids:
                      debug_log(f"â­ï¸ Skipping cached post: {post.id}")
                      continue
                  try:
                      ext = os.path.splitext(post.url.lower())[1]
                      if ext in valid_image_exts:
                          debug_log(f"ğŸ“· Found image post: {post.id}")
                          r = requests.get(post.url, timeout=10)
                          r.raise_for_status()
                          out_fname = os.path.join("cache", f"{post.id}{ext}")
                          with open(out_fname, "wb") as f:
                              f.write(r.content)
                          memes_metadata.append({
                              "id": post.id,
                              "title": post.title,
                              "author": str(post.author) if post.author else "Unknown",
                              "subreddit": str(post.subreddit),
                              "upvotes": post.ups,
                              "filename": os.path.basename(out_fname),
                              "type": "image"
                          })
                          new_ids.append(post.id)
                          total_memes += 1
                          debug_log(f"âœ… Downloaded image: {out_fname}")
                      else:
                          debug_log(f"ğŸ¥ Found potential video post: {post.id}")
                          outtmpl = f"cache/{post.id}.%(ext)s"
                          ydl_opts = {
                            'outtmpl': outtmpl,
                            'quiet': not show_debug,            # Keeps quiet when not in debug mode
                            'no_warnings': True,               # Suppresses warnings
                            'ignoreerrors': True,              # Continues on download errors
                            'format': 'bestvideo+bestaudio/best',  # Selects the best video and audio
                            'merge_output_format': 'mp4',      # Merges into mp4 format
                            'no-progress': True,               # Disables the progress bar
                            'loglevel': 'error',                # Sets log level to show only errors
                          }
                          with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                              ydl.download([post.url])
                          downloaded_file = None
                          for file in os.listdir("cache"):
                              if file.startswith(post.id):
                                  downloaded_file = os.path.join("cache", file)
                                  break
                          if downloaded_file:
                              debug_log(f"ğŸ“¹ Downloaded video: {downloaded_file}")
                              memes_metadata.append({
                                  "id": post.id,
                                  "title": post.title,
                                  "author": str(post.author) if post.author else "Unknown",
                                  "subreddit": str(post.subreddit),
                                  "upvotes": post.ups,
                                  "filename": os.path.basename(downloaded_file),
                                  "type": "video"
                              })
                              new_ids.append(post.id)
                              total_memes += 1
                              debug_log(f"âœ… Processed video post: {post.id}")
                          else:
                              print(f"âš ï¸ Post {post.id}: Could not save as image or video - skipping.")
                  except Exception as e:
                      print(f"âš ï¸ Error processing post {post.id}: {e}")

          if new_ids:
              cached_ids.update(new_ids)
              with open(cache_file, "w") as f:
                  json.dump(sorted(cached_ids), f)
              print(f"ğŸ‰ Downloaded {len(new_ids)} new items.")
          else:
              print("âœ¨ No New Items Found!")
          with open("cache/memes_metadata.json", "w") as f:
              json.dump(memes_metadata, f, indent=2)
          debug_log("ğŸ“„ Memes metadata collected.")
          EOF

      - name: ğŸ—‚ï¸ Collect Metadata
        id: collect-metadata
        run: |
          echo "ğŸ“Š [DEBUG] Collecting metadata..."
          # Limit to first 250 memes to prevent matrix overflow
          limited_metadata=$(jq '.[:250]' cache/memes_metadata.json)
          metadata=$(echo "$limited_metadata" | jq -c .)
          echo "metadata=$metadata" >> $GITHUB_OUTPUT
          echo "âœ… [DEBUG] Metadata collection complete."

      - name: ğŸŒ Upload Memes with Rclone
        run: |
          echo "ğŸ”„ [DEBUG] Uploading memes to Pixeldrain with Rclone..."
          rclone copy cache Pixeldrain:"ğŸ’¯ Memes"
          echo "âœ… [DEBUG] Upload complete."

      - name: ğŸ”§ Compute Hash of Updated meme_ids.json
        id: compute-hash
        run: |
          echo "ğŸ” [DEBUG] Computing hash of meme_ids.json..."
          if [ -f cache/meme_ids.json]; then
            FILE_HASH=$(sha256sum cache/meme_ids.json | awk '{print $1}')
            echo "ğŸ”‘ [DEBUG] Computed hash: $FILE_HASH"
          else
            FILE_HASH="empty-cache"
            echo "âš ï¸ [DEBUG] meme_ids.json not found. Using default hash."
          fi
          echo "hash=$FILE_HASH" >> $GITHUB_ENV

      - name: ğŸ’¾ Update Meme IDs Cache
        uses: actions/cache@v4
        with:
          path: cache/meme_ids.json
          key: meme-ids-cache-${{ env.hash }}

      - name: ğŸ“œ List All Files
        run: |
          echo "ğŸ“‚ [DEBUG] Listing all files in cache..."
          tree
          echo "âœ… [DEBUG] File listing complete."

      - name: ğŸ“¤ Upload Cache as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: cache
          path: cache/

  send-to-telegram:
    needs: download-memes
    name: ğŸ“¤ Send All Memes to Telegram
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Check Out Repository
        uses: actions/checkout@v4

      - name: ğŸ“¤ Download Cache Artifact
        uses: actions/download-artifact@v4
        with:
          name: cache
          path: cache/

      - name: ğŸ“¦ Set Up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: ğŸ§° Install Python Dependencies
        run: |
          echo "ğŸ“¦ [DEBUG] Installing python-telegram-bot..."
          pip install python-telegram-bot
          echo "âœ… [DEBUG] Python dependencies installed."

      - name: ğŸ“¤ Send Memes in One Script
        run: |
          echo "ğŸ“¤ [DEBUG] Starting to send memes to Telegram..."
          python - <<'EOF'
          import os
          import re
          import json
          import asyncio
          from telegram import Bot

          BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
          CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
          METADATA_FILE = 'cache/memes_metadata.json'

          def escape_markdown(text):
              """Escapes Markdown-sensitive characters."""
              escape_chars = r"_*[]()~`>#+-=|{}.!"
              return re.sub(f'([{"".join(re.escape(c) for c in escape_chars)}])', r'\\\1', text)

          def build_caption(meme):
              if meme['type'] == 'image':
                  return f"""ğŸ‰ **New Meme Alert!**
                  ğŸ“œ *Title:* {escape_markdown(meme.get('title', 'No Title'))}
                  ğŸ–‹ï¸ *Author:* {escape_markdown(meme.get('author', 'Unknown'))}
                  ğŸ‘ *Upvotes:* {meme.get('upvotes', '0')}
                  ğŸ”— *URL:* [View Post]({meme.get('url', '')})
                  ğŸ·ï¸ *Subreddit:* r/{escape_markdown(meme.get('subreddit', '?'))}"""
              else:
                  return f"""ğŸ‰ **New Video Meme Alert!**
                  ğŸ“œ *Title:* {escape_markdown(meme.get('title', 'No Title'))}
                  ğŸ–‹ï¸ *Author:* {escape_markdown(meme.get('author', 'Unknown'))}
                  ğŸ‘ *Upvotes:* {meme.get('upvotes', '0')}
                  ğŸ”— *URL:* [View Post]({meme.get('url', '')})
                  ğŸ·ï¸ *Subreddit:* r/{escape_markdown(meme.get('subreddit', '?'))}"""

          async def send_meme_async(bot, meme):
              file_path = os.path.join('cache', meme['filename'])
              caption = build_caption(meme)
              if meme['type'] == 'image':
                  with open(file_path, 'rb') as img:
                      await bot.send_photo(
                          chat_id=CHAT_ID,
                          photo=img,
                          caption=caption,
                          parse_mode='Markdown'
                      )
                      print(f"ğŸ“· [DEBUG] Sent image meme ID: {meme['id']}")
              elif meme['type'] == 'video':
                  with open(file_path, 'rb') as vid:
                      await bot.send_video(
                          chat_id=CHAT_ID,
                          video=vid,
                          caption=caption,
                          parse_mode='Markdown',
                          supports_streaming=True
                      )
                      print(f"ğŸ¥ [DEBUG] Sent video meme ID: {meme['id']}")

          async def main():
              bot = Bot(token=BOT_TOKEN)
              if not os.path.exists(METADATA_FILE):
                  print("âš ï¸ [DEBUG] No metadata file found. Nothing to send.")
                  return

              with open(METADATA_FILE, 'r') as f:
                  memes = json.load(f)
              print(f"ğŸ“š [DEBUG] Loaded {len(memes)} memes from metadata.")

              for meme in memes:
                  try:
                      await send_meme_async(bot, meme)
                  except Exception as e:
                      print(f"âŒ [DEBUG] Failed to send meme ID {meme['id']}: {e}")

              print("âœ… [DEBUG] All memes have been processed.")

          if __name__ == '__main__':
              try:
                  asyncio.run(main())
              except Exception as e:
                  print(f"âŒ [DEBUG] Error sending memes in batch: {e}")
          EOF
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_TO }}
        continue-on-error: true
